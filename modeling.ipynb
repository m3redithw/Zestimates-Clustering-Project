{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9437c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "\n",
    "# set columnns display format\n",
    "pd.set_option('display.max_columns', None)\n",
    "# default pandas decimal number display format\n",
    "# pd.options.display.float_format = '{:20,.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a08cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw, messy data\n",
    "df = acquire.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "910897be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "df = prepare.prep_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db97f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and split the data\n",
    "train, validate, test = prepare.split_scale(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f4911",
   "metadata": {},
   "source": [
    "## Adding Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This funcion adds location clusters to dataframe\n",
    "def location_clusers(train, validate, test):\n",
    "    cols = ['latitude', 'longitude', 'zip_bin_insgfnt high', 'zip_bin_insgfnt low',\n",
    "       'zip_bin_sgfnt high']\n",
    "    kmeans = KMeans(n_clusters=4)\n",
    "    kmeans.fit(train[cols])\n",
    "    train['location_clusters'] = kmeans.predict(train[cols])\n",
    "    validate['location_clusters'] = kmeans.predict(validate[cols])\n",
    "    test['location_clusters'] = kmeans.predict(test[cols])\n",
    "    train.location_clusters = train.location_clusters.astype('str')\n",
    "    validate.location_clusters = validate.location_clusters.astype('str')\n",
    "    test.location_clusters  = test.location_clusters.astype('str')\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This funcion adds age clusters to dataframe\n",
    "def age_clusters(train, validate, test):\n",
    "    cols = ['age']\n",
    "    kmeans = KMeans(n_clusters=3)\n",
    "    kmeans.fit(train[cols])\n",
    "\n",
    "    train['age_clusters'] = kmeans.predict(train[cols])\n",
    "    validate['age_clusters'] = kmeans.predict(validate[cols])\n",
    "    test['age_clusters'] = kmeans.predict(test[cols])\n",
    "    \n",
    "    train.age_clusters = train.age_clusters.astype('str')\n",
    "    validate.age_clusters = validate.age_clusters.astype('str')\n",
    "    test.age_clusters  = test.age_clusters.astype('str')\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This funcion adds area clusters to dataframe\n",
    "def area_clusters(train, validate, test):\n",
    "    cols =['total_sqft', 'lot_sqft', 'living_sqft']\n",
    "    kmeans = KMeans(n_clusters=3)\n",
    "    kmeans.fit(train[cols])\n",
    "\n",
    "    train['area_clusters'] = kmeans.predict(train[cols])\n",
    "    validate['area_clusters'] = kmeans.predict(validate[cols])\n",
    "    test['area_clusters'] = kmeans.predict(test[cols])\n",
    "    \n",
    "    train.area_clusters = train.area_clusters.astype('str')\n",
    "    validate.area_clusters = validate.area_clusters.astype('str')\n",
    "    test.area_clusters  = test.area_clusters.astype('str')\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "148918b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This funcion adds size clusters to dataframe\n",
    "def size_clusters(train, validate, test):\n",
    "    cols = ['bedrooms', 'bathrooms', 'full_bath']\n",
    "    kmeans = KMeans(n_clusters=3)\n",
    "    kmeans.fit(train[cols])\n",
    "    \n",
    "    train['size_clusters'] = kmeans.predict(train[cols])\n",
    "    validate['size_clusters'] = kmeans.predict(validate[cols])\n",
    "    test['size_clusters'] = kmeans.predict(test[cols])\n",
    "    \n",
    "    train.size_clusters = train.size_clusters.astype('str')\n",
    "    validate.size_clusters = validate.size_clusters.astype('str')\n",
    "    test.size_clusters  = test.size_clusters.astype('str')\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This funcion adds value clusters to dataframe\n",
    "def value_clusters(train, validate, test):\n",
    "    # adding value clusters to dataframe - not significant\n",
    "\n",
    "    cols = ['structure_value', 'assessed_value', 'land_value','taxamount']\n",
    "    kmeans = KMeans(n_clusters=3)\n",
    "    kmeans.fit(train[cols])\n",
    "    train['value_clusters'] = kmeans.predict(train[cols])\n",
    "    validate['value_clusters'] = kmeans.predict(validate[cols])\n",
    "    test['value_clusters'] = kmeans.predict(test[cols])\n",
    "    train.value_clusters = train.value_clusters.astype('str')\n",
    "    validate.value_clusters = validate.value_clusters.astype('str')\n",
    "    test.value_clusters  = test.value_clusters.astype('str')\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates dummy variables of clusters columns\n",
    "def clusters_dummy(train, validate_test):\n",
    "    cols = ['location_clusters', 'age_clusters', 'area_clusters', 'size_clusters', 'value_clusters']\n",
    "    train_dummy = pd.get_dummies(train[cols], dummy_na=False, drop_first=False)\n",
    "    train = pd.concat([train, train_dummy], axis=1)\n",
    "\n",
    "    validate_dummy = pd.get_dummies(validate[cols], dummy_na=False, drop_first=False)\n",
    "    validate = pd.concat([validate, validate_dummy], axis=1)\n",
    "\n",
    "    test_dummy = pd.get_dummies(test[cols], dummy_na=False, drop_first=False)\n",
    "    test = pd.concat([test, test_dummy], axis=1)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940408d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding location clusters A to dataframe\n",
    "cols = ['latitude', 'longitude', 'zip_bin_insgfnt high', 'zip_bin_insgfnt low',\n",
    "       'zip_bin_sgfnt high']\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(train[cols])\n",
    "\n",
    "train['location_clusters'] = kmeans.predict(train[cols])\n",
    "validate['location_clusters'] = kmeans.predict(validate[cols])\n",
    "test['location_clusters'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bf9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding age cluster A to dataframe\n",
    "cols = ['age']\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(train[cols])\n",
    "\n",
    "train['age_clusters'] = kmeans.predict(train[cols])\n",
    "validate['age_clusters'] = kmeans.predict(validate[cols])\n",
    "test['age_clusters'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d2df917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding area clusters to dataframe - somewhat significant\n",
    "\n",
    "cols =['total_sqft', 'lot_sqft', 'living_sqft']\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(train[cols])\n",
    "\n",
    "train['area_clusters'] = kmeans.predict(train[cols])\n",
    "validate['area_clusters'] = kmeans.predict(validate[cols])\n",
    "test['area_clusters'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8341753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding size clusters A to dataframe - not significant\n",
    "\n",
    "cols = ['bedrooms', 'bathrooms', 'full_bath']\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(train[cols])\n",
    "train['size_clusters'] = kmeans.predict(train[cols])\n",
    "validate['size_clusters'] = kmeans.predict(validate[cols])\n",
    "test['size_clusters'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1afc1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding value clusters to dataframe - not significant\n",
    "\n",
    "cols = ['structure_value', 'assessed_value', 'land_value','taxamount']\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(train[cols])\n",
    "train['value_clusters'] = kmeans.predict(train[cols])\n",
    "validate['value_clusters'] = kmeans.predict(validate[cols])\n",
    "test['value_clusters'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d616b",
   "metadata": {},
   "source": [
    "## Feature Combination Experimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcaabd1",
   "metadata": {},
   "source": [
    "### cols = ['age_clusters_0', 'age_clusters_1', 'age_clusters_2','location_clusters_0', 'location_clusters_1',  'location_clusters_2', 'location_clusters_3','total_sqft','lot_sqft','size_clusters_0','size_clusters_1', 'size_clusters_2', 'value_clusters_0', 'value_clusters_1', 'value_clusters_2']\n",
    "\n",
    "**Polynomial k=2 interaction only**\n",
    "(0.161358448910367, 0.15736544905806119, 0.17749488159077875)\n",
    "\n",
    "### cols = ['age_clusters_0', 'age_clusters_1', 'age_clusters_2','location_clusters_0', 'location_clusters_1',  'location_clusters_2', 'location_clusters_3','total_sqft','lot_sqft','size_clusters_0','size_clusters_1', 'size_clusters_2', 'value_clusters_0', 'value_clusters_1', 'value_clusters_2', transaction_month]\n",
    "\n",
    "**Multiple Regression**\n",
    "Train: \n",
    "(multiple_rfe_k=, 14)    0.161642\n",
    "(multiple_rfe_k=, 15)    0.161643\n",
    "(multiple_rfe_k=, 12)    0.161731\n",
    "(multiple_rfe_k=, 13)    0.161733\n",
    "(multiple_rfe_k=, 11)    0.161903\n",
    "(multiple_rfe_k=, 10)    0.162281\n",
    "\n",
    "Validate:\n",
    "(multiple_rfe_k=, 15)    0.157321\n",
    "(multiple_rfe_k=, 14)    0.157337\n",
    "(multiple_rfe_k=, 12)    0.157391\n",
    "(multiple_rfe_k=, 13)    0.157399\n",
    "(multiple_rfe_k=, 11)    0.157469\n",
    "(multiple_rfe_k=, 9)     0.157945\n",
    "\n",
    "Test:\n",
    "**(multiple_rfe_k=, 15)    0.177476**\n",
    "(multiple_rfe_k=, 14)    0.177482\n",
    "(multiple_rfe_k=, 13)    0.177561\n",
    "(multiple_rfe_k=, 12)    0.177565\n",
    "(multiple_rfe_k=, 11)    0.177579\n",
    "(multiple_rfe_k=, 10)    0.178128\n",
    "\n",
    "Polynomial k=2\n",
    "(0.16106354262688366, 0.15743867746183518, 0.17749013551486467)\n",
    "Polynomial k=2 interaction\n",
    "(0.1611540173986898, 0.15744241883135332, 0.1774858420240756)\n",
    "\n",
    "### cols = ['living_sqft', 'structure_value', 'assessed_value', 'land_value', 'zip_bin_insgfnt high', 'zip_bin_sgfnt high', 'location_clusters_0', 'location_clusters_2', 'location_clusters_3', 'value_clusters_0']\n",
    "\n",
    "Multiple regression: \n",
    "(multiple_rfe_k=, 9)    0.161627\n",
    "(multiple_rfe_k=, 7)    0.161640\n",
    "(multiple_rfe_k=, 8)    0.161640\n",
    "(multiple_rfe_k=, 6)    0.161650\n",
    "(multiple_rfe_k=, 4)    0.161820\n",
    "(multiple_rfe_k=, 5)    0.161820\n",
    "(multiple_rfe_k=, 3)    0.161996\n",
    "(multiple_rfe_k=, 2)    0.162445\n",
    "baseline                0.162624\n",
    "\n",
    "(multiple_rfe_k=, 9)    0.157305\n",
    "(multiple_rfe_k=, 7)    0.157336\n",
    "(multiple_rfe_k=, 8)    0.157336\n",
    "(multiple_rfe_k=, 6)    0.157388\n",
    "(multiple_rfe_k=, 3)    0.157633\n",
    "(multiple_rfe_k=, 4)    0.157658\n",
    "(multiple_rfe_k=, 5)    0.157658\n",
    "(multiple_rfe_k=, 2)    0.157899\n",
    "basline                 0.158068\n",
    "\n",
    "(multiple_rfe_k=, 9)    0.177428\n",
    "(multiple_rfe_k=, 6)    0.177436\n",
    "(multiple_rfe_k=, 7)    0.177443\n",
    "(multiple_rfe_k=, 8)    0.177443\n",
    "(multiple_rfe_k=, 4)    0.177781\n",
    "(multiple_rfe_k=, 5)    0.177781\n",
    "(multiple_rfe_k=, 3)    0.177918\n",
    "(multiple_rfe_k=, 2)    0.178179\n",
    "baseline                0.178470\n",
    "\n",
    "**Polynomial k=2:\n",
    "(0.16151388904167482, 0.15735778462696057, 0.1774465577764435)**\n",
    "\n",
    "### cols = ['living_sqft', 'structure_value', 'assessed_value', 'land_value',  'county_Los Angeles', 'county_Orange', 'county_Ventura', 'zip_bin_insgfnt high', 'zip_bin_sgfnt high', 'location_clusters_0', 'location_clusters_2', 'location_clusters_3', 'age_clusters_0',  'area_clusters_1', 'area_clusters_2', 'size_clusters_0', 'value_clusters_0']\n",
    "\n",
    "**Multiple Regression**\n",
    "Train:\n",
    "(multiple_rfe_k=, 15)    0.161580\n",
    "(multiple_rfe_k=, 14)    0.161580\n",
    "(multiple_rfe_k=, 12)    0.161582\n",
    "(multiple_rfe_k=, 13)    0.161582\n",
    "(multiple_rfe_k=, 11)    0.161589\n",
    "\n",
    "Validate:\n",
    "(multiple_rfe_k=, 7)     0.157336\n",
    "(multiple_rfe_k=, 8)     0.157336\n",
    "(multiple_rfe_k=, 9)     0.157342\n",
    "(multiple_rfe_k=, 11)    0.157371\n",
    "(multiple_rfe_k=, 12)    0.157374\n",
    "\n",
    "Test:\n",
    "(multiple_rfe_k=, 6)     0.177436\n",
    "(multiple_rfe_k=, 7)     0.177443\n",
    "(multiple_rfe_k=, 8)     0.177443\n",
    "(multiple_rfe_k=, 9)     0.177451\n",
    "\n",
    "**Polynomial k=2\n",
    "(0.16118663037140582, 0.15752054355182657, 0.17757655954543025)**\n",
    "\n",
    "\n",
    "       \n",
    "### cols = ['living_sqft', 'structure_value', 'assessed_value', 'land_value', 'county_Los Angeles', 'county_Orange', 'county_Ventura','zip_bin_insgfnt high', 'zip_bin_sgfnt high', 'age_clusters_0', 'area_clusters_1', 'area_clusters_2', 'size_clusters_0']\n",
    "\n",
    "**Multiple regression:**\n",
    "Train:\n",
    "(multiple_rfe_k=, 6)    0.161759\n",
    "(multiple_rfe_k=, 7)    0.161759\n",
    "(multiple_rfe_k=, 5)    0.161809\n",
    "(multiple_rfe_k=, 4)    0.161819\n",
    "(multiple_rfe_k=, 3)    0.162205\n",
    "(multiple_rfe_k=, 2)    0.162445\n",
    "baseline                0.162624\n",
    "\n",
    "Validate:\n",
    "(multiple_rfe_k=, 5)    0.157396\n",
    "(multiple_rfe_k=, 4)    0.157447\n",
    "(multiple_rfe_k=, 6)    0.157465\n",
    "(multiple_rfe_k=, 7)    0.157465\n",
    "(multiple_rfe_k=, 2)    0.157899\n",
    "(multiple_rfe_k=, 3)    0.157910\n",
    "basline                 0.158068\n",
    "\n",
    "Test:\n",
    "(multiple_rfe_k=, 4)    0.177443\n",
    "(multiple_rfe_k=, 5)    0.177449\n",
    "(multiple_rfe_k=, 6)    0.177509\n",
    "(multiple_rfe_k=, 7)    0.177509\n",
    "(multiple_rfe_k=, 3)    0.178001\n",
    "(multiple_rfe_k=, 2)    0.178179\n",
    "baseline                0.178470\n",
    "\n",
    "Polynomial interaction only k=2:\n",
    "(0.1614473947647387, 0.15759616934697873, 0.17765691560020958)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06718168",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = ['bathrooms', 'bedrooms', 'total_sqft', 'living_sqft',\n",
    "       'full_bath', 'latitude', 'longitude', 'lot_sqft', 'roomcnt',\n",
    "       'structure_value', 'assessed_value', 'land_value', 'taxamount','age', 'taxrate', 'transaction_month',\n",
    "       'county_Los Angeles', 'county_Orange', 'county_Ventura', 'zip_code', 'zip_bin_insgfnt high', 'zip_bin_insgfnt low',\n",
    "       'zip_bin_sgfnt high', 'zip_bin_sgfnt low', 'location_clusters',\n",
    "       'age_clusters', 'area_clusters', 'size_clusters', 'value_clusters',\n",
    "       'location_clusters_0', 'location_clusters_1', 'location_clusters_2',\n",
    "       'location_clusters_3', 'age_clusters_0', 'age_clusters_1',\n",
    "       'age_clusters_2', 'area_clusters_0', 'area_clusters_1',\n",
    "       'area_clusters_2', 'size_clusters_0', 'size_clusters_1',\n",
    "       'size_clusters_2', 'value_clusters_0', 'value_clusters_1',\n",
    "       'value_clusters_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8cd0990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set x and y\n",
    "cols = ['total_sqft', 'living_sqft', 'structure_value', 'assessed_value',\n",
    "       'land_value', 'zip_bin_insgfnt high', 'zip_bin_sgfnt low', 'size_clusters', 'value_clusters',\n",
    "       'location_clusters_3', 'age_clusters_0', 'age_clusters_1',\n",
    "       'area_clusters_0', 'area_clusters_1', 'area_clusters_2',\n",
    "       'size_clusters_0', 'size_clusters_1', 'value_clusters_1','county_Los Angeles', 'county_Orange',\n",
    "       'value_clusters_2']\n",
    "X_train = train[cols]\n",
    "y_train = train.logerror\n",
    "\n",
    "X_validate = validate[cols]\n",
    "y_validate = validate.logerror\n",
    "\n",
    "X_test = test[cols]\n",
    "y_test = test.logerror"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3e089",
   "metadata": {},
   "source": [
    "## Multiple  Regression + RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "522cb166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected top 6 features: Index(['total_sqft', 'living_sqft', 'structure_value', 'assessed_value',\n",
      "       'land_value', 'zip_bin_insgfnt high', 'zip_bin_sgfnt low',\n",
      "       'location_clusters', 'size_clusters', 'value_clusters',\n",
      "       'location_clusters_3', 'age_clusters_0', 'age_clusters_1',\n",
      "       'area_clusters_0', 'area_clusters_1', 'area_clusters_2',\n",
      "       'size_clusters_0', 'size_clusters_1', 'value_clusters_1',\n",
      "       'value_clusters_2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=20)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 6 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "61b33429",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = pd.DataFrame({\n",
    "    'actual': train.logerror\n",
    "}) \n",
    "validate_predictions = pd.DataFrame({\n",
    "    'actual': validate.logerror\n",
    "})\n",
    "test_predictions = pd.DataFrame({\n",
    "    'actual': test.logerror\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d0000b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions['baseline'] = y_train.mean()\n",
    "validate_predictions['basline']=y_validate.mean()\n",
    "test_predictions['baseline']=y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fb83e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,20):\n",
    "    lm = LinearRegression()\n",
    "    # 1. Transform our X\n",
    "    rfe = RFE(lm, n_features_to_select=k)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    # 2. Use the transformed x in our model\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_validate_rfe = rfe.transform(X_validate)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    lm.fit(X_train_rfe, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions['multiple_rfe_k=', k] = lm.predict(X_train_rfe)\n",
    "    validate_predictions['multiple_rfe_k=', k] = lm.predict(X_validate_rfe)\n",
    "    test_predictions['multiple_rfe_k=', k] = lm.predict(X_test_rfe)\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7403f993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual                   0.000000\n",
       "(multiple_rfe_k=, 19)    0.161572\n",
       "(multiple_rfe_k=, 18)    0.161578\n",
       "(multiple_rfe_k=, 17)    0.161615\n",
       "(multiple_rfe_k=, 16)    0.161791\n",
       "(multiple_rfe_k=, 15)    0.161966\n",
       "(multiple_rfe_k=, 13)    0.162423\n",
       "(multiple_rfe_k=, 14)    0.162423\n",
       "(multiple_rfe_k=, 12)    0.162470\n",
       "(multiple_rfe_k=, 11)    0.162476\n",
       "(multiple_rfe_k=, 10)    0.162476\n",
       "(multiple_rfe_k=, 9)     0.162518\n",
       "(multiple_rfe_k=, 8)     0.162518\n",
       "(multiple_rfe_k=, 7)     0.162522\n",
       "(multiple_rfe_k=, 6)     0.162569\n",
       "(multiple_rfe_k=, 5)     0.162569\n",
       "(multiple_rfe_k=, 4)     0.162576\n",
       "(multiple_rfe_k=, 2)     0.162602\n",
       "(multiple_rfe_k=, 3)     0.162602\n",
       "baseline                 0.162624\n",
       "dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train performance\n",
    "def calculate_rmse(y_predicted):\n",
    "    return mean_squared_error(train_predictions.actual, y_predicted, squared = False)\n",
    "\n",
    "train_predictions.apply(calculate_rmse).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec8ac6a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual                   0.000000\n",
       "(multiple_rfe_k=, 17)    0.157328\n",
       "(multiple_rfe_k=, 18)    0.157386\n",
       "(multiple_rfe_k=, 19)    0.157407\n",
       "(multiple_rfe_k=, 15)    0.157589\n",
       "(multiple_rfe_k=, 16)    0.157624\n",
       "(multiple_rfe_k=, 13)    0.157877\n",
       "(multiple_rfe_k=, 14)    0.157881\n",
       "(multiple_rfe_k=, 10)    0.157881\n",
       "(multiple_rfe_k=, 11)    0.157883\n",
       "(multiple_rfe_k=, 12)    0.157908\n",
       "(multiple_rfe_k=, 7)     0.157935\n",
       "(multiple_rfe_k=, 9)     0.157939\n",
       "(multiple_rfe_k=, 8)     0.157941\n",
       "(multiple_rfe_k=, 2)     0.158018\n",
       "(multiple_rfe_k=, 3)     0.158018\n",
       "(multiple_rfe_k=, 4)     0.158036\n",
       "(multiple_rfe_k=, 6)     0.158037\n",
       "(multiple_rfe_k=, 5)     0.158037\n",
       "basline                  0.158068\n",
       "dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate performance\n",
    "def calculate_rmse(y_predicted):\n",
    "    return mean_squared_error(validate_predictions.actual, y_predicted, squared = False)\n",
    "\n",
    "validate_predictions.apply(calculate_rmse).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d8207137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual                   0.000000\n",
       "(multiple_rfe_k=, 17)    0.177467\n",
       "(multiple_rfe_k=, 19)    0.177489\n",
       "(multiple_rfe_k=, 18)    0.177511\n",
       "(multiple_rfe_k=, 16)    0.177817\n",
       "(multiple_rfe_k=, 15)    0.177955\n",
       "(multiple_rfe_k=, 13)    0.178215\n",
       "(multiple_rfe_k=, 14)    0.178222\n",
       "(multiple_rfe_k=, 12)    0.178305\n",
       "(multiple_rfe_k=, 11)    0.178308\n",
       "(multiple_rfe_k=, 10)    0.178313\n",
       "(multiple_rfe_k=, 7)     0.178347\n",
       "(multiple_rfe_k=, 4)     0.178353\n",
       "(multiple_rfe_k=, 6)     0.178356\n",
       "(multiple_rfe_k=, 5)     0.178356\n",
       "(multiple_rfe_k=, 9)     0.178357\n",
       "(multiple_rfe_k=, 8)     0.178359\n",
       "(multiple_rfe_k=, 2)     0.178366\n",
       "(multiple_rfe_k=, 3)     0.178366\n",
       "baseline                 0.178470\n",
       "dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test performance\n",
    "def calculate_rmse(y_predicted):\n",
    "    return mean_squared_error(test_predictions.actual, y_predicted, squared = False)\n",
    "\n",
    "test_predictions.apply(calculate_rmse).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41882470",
   "metadata": {},
   "source": [
    "## Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5f5558a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = pd.DataFrame({\n",
    "    'actual': train.logerror\n",
    "}) \n",
    "validate_pred = pd.DataFrame({\n",
    "    'actual': validate.logerror\n",
    "})\n",
    "test_pred = pd.DataFrame({\n",
    "    'actual': test.logerror\n",
    "})\n",
    "train_pred['baseline'] = y_train.mean()\n",
    "validate_pred['basline']=y_validate.mean()\n",
    "test_pred['basline']=y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "05acff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# 1. Generate Polynomial Features, k=2\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=X_train.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d2e161a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "train_pred['polynomial degree 2'] = lm.predict(X_train_poly)\n",
    "validate_pred['polynomial degree 2'] = lm.predict(X_validate_poly)\n",
    "test_pred['polynomial degree 2'] = lm.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3c3cb160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16104810550111515, 0.1576209758222008, 0.17776502622199108)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(train_pred.actual,train_pred['polynomial degree 2'], squared = False)\n",
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['polynomial degree 2'], squared = False)\n",
    "test_rmse = mean_squared_error(test_pred.actual,test_pred['polynomial degree 2'], squared = False)\n",
    "train_rmse, validate_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0f1eb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction terms only\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=X_train.index,\n",
    ")\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "train_pred['polynomial degree 2 only interaction'] = lm.predict(X_train_poly)\n",
    "validate_pred['polynomial degree 2 only interaction'] = lm.predict(X_validate_poly)\n",
    "test_pred['polynomial degree 2 only interaction'] = lm.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "66548c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16105044421493095, 0.1576112318944588, 0.1777685105568272)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(train_pred.actual,train_pred['polynomial degree 2 only interaction'], squared = False)\n",
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['polynomial degree 2 only interaction'], squared = False)\n",
    "test_rmse = mean_squared_error(test_pred.actual,test_pred['polynomial degree 2 only interaction'], squared = False)\n",
    "train_rmse, validate_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "198cef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=3\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=X_train.index,\n",
    ")\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "train_pred['polynomial degree 3'] = lm.predict(X_train_poly)\n",
    "validate_pred['polynomial degree 3'] = lm.predict(X_validate_poly)\n",
    "test_pred['polynomial degree 3'] = lm.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a89e075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15991225818909532, 946338868.5088542, 0.1789728908845889)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(train_pred.actual,train_pred['polynomial degree 3'], squared = False)\n",
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['polynomial degree 3'], squared = False)\n",
    "test_rmse = mean_squared_error(test_pred.actual,test_pred['polynomial degree 3'], squared = False)\n",
    "train_rmse, validate_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f77bce",
   "metadata": {},
   "source": [
    "## Lasso-Lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06fa1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=1)\n",
    "\n",
    "# fit the model to our training data\n",
    "lars.fit(X_train, y_train)\n",
    "\n",
    "# predict validate\n",
    "X_train_pred_lars = lars.predict(X_train)\n",
    "X_validate_pred_lars = lars.predict(X_validate)\n",
    "X_test_pred_lars = lars.predict(X_test)\n",
    "# Add lassolars predictions to our predictions DataFrame\n",
    "train_pred['lasso_lars'] = X_train_pred_lars\n",
    "validate_pred['lasso_lars'] = X_validate_pred_lars\n",
    "test_pred['lasso_lars'] = X_test_pred_lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b5d4cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16262411066536314, 0.1580787480680725, 0.1784697030682737)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(train_pred.actual,train_pred['lasso_lars'], squared = False)\n",
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['lasso_lars'], squared = False)\n",
    "test_rmse = mean_squared_error(test_pred.actual,test_pred['lasso_lars'], squared = False)\n",
    "train_rmse, validate_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91d5f3",
   "metadata": {},
   "source": [
    "## Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_prediction(s_train, s_validate, s_test):\n",
    "    # Initialized dataframe to hold preditions from different models\n",
    "    train_predictions = pd.DataFrame({\n",
    "        'actual': train.logerror}) \n",
    "    validate_predictions = pd.DataFrame({\n",
    "        'actual': validate.logerror})\n",
    "    test_predictions = pd.DataFrame({\n",
    "        'actual': test.logerror})\n",
    "    \n",
    "    # Adding baseline predictions to dataframes\n",
    "    train_predictions['baseline'] = y_train.mean()\n",
    "    validate_predictions['basline']=y_validate.mean()\n",
    "    test_predictions['baseline']=y_test.mean()\n",
    "    \n",
    "    # Print baseline rmse for train dataset's baseline\n",
    "    rmse = mean_squared_error(train_predictions.actual, train_predictions.baseline, squared = False)\n",
    "    print(Fore.BLUE+ \"\\nRoot mean of squared error of baseline prediction is: \", \"{:10.2f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_a_models(train, validate, test, train_predictions, validate_predictions, test_predictions):\n",
    "    cols = ['age_clusters_0', 'age_clusters_1', 'age_clusters_2','location_clusters_0',\n",
    "            'location_clusters_1',  'location_clusters_2', 'location_clusters_3',\n",
    "            'total_sqft','lot_sqft','size_clusters_0','size_clusters_1', 'size_clusters_2',\n",
    "            'value_clusters_0', 'value_clusters_1', 'value_clusters_2', 'transaction_month']\n",
    "    X_train = train[cols]\n",
    "    y_train = train.logerror\n",
    "\n",
    "    X_validate = validate[cols]\n",
    "    y_validate = validate.logerror\n",
    "\n",
    "    X_test = test[cols]\n",
    "    y_test = test.logerror\n",
    "    # Notes: I looped through k and found out the model performs the best when k=15\n",
    "    # Initiate the linear regression model\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    # Transform our X\n",
    "    rfe = RFE(lm, n_features_to_select=7)\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Use the transformed x in our model\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_validate_rfe = rfe.transform(X_validate)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    lm.fit(X_train_rfe, y_train)\n",
    "\n",
    "    # Make predictions and add that to the train_predictions dataframe\n",
    "    train_predictions['feature a multiple_rfe_k=15'] = lm.predict(X_train_rfe)\n",
    "    validate_predictions['feature a multiple_rfe_k=15', k] = lm.predict(X_validate_rfe)\n",
    "    test_predictions['feature a multiple_rfe_k=15', k] = lm.predict(X_test_rfe)\n",
    "    \n",
    "    # Polynomial degree 2 interaction terms only\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "    poly.fit(X_train)\n",
    "    X_train_poly = pd.DataFrame(\n",
    "        poly.transform(X_train),\n",
    "        columns=poly.get_feature_names(X_train.columns),\n",
    "        index=X_train.index,\n",
    "    )\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train_poly, y_train)\n",
    "\n",
    "    X_validate_poly = poly.transform(X_validate)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    train_predictions['feature a polynomial degree 2 only interaction'] = lm.predict(X_train_poly)\n",
    "    validate_predictions['feature a polynomial degree 2 only interaction'] = lm.predict(X_validate_poly)\n",
    "    test_predictions['feature a polynomial degree 2 only interaction'] = lm.predict(X_test_poly)\n",
    "    \n",
    "    return train_predictions, validate_predictions, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_b_models(train, validate, test, train_predictions, validate_predictions, test_predictions):\n",
    "    cols = ['living_sqft', 'structure_value', 'assessed_value', 'land_value',\n",
    "       'zip_bin_insgfnt high', 'zip_bin_sgfnt high', 'location_clusters_0',\n",
    "       'location_clusters_2', 'location_clusters_3', 'value_clusters_0']\n",
    "    X_train = train[cols]\n",
    "    y_train = train.logerror\n",
    "\n",
    "    X_validate = validate[cols]\n",
    "    y_validate = validate.logerror\n",
    "\n",
    "    X_test = test[cols]\n",
    "    y_test = test.logerror\n",
    "    \n",
    "    # Notes: I looped through k and found out the model performs the best when k=9\n",
    "    # Initiate the linear regression model\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    # Transform our X\n",
    "    rfe = RFE(lm, n_features_to_select=9)\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Use the transformed x in our model\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_validate_rfe = rfe.transform(X_validate)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    lm.fit(X_train_rfe, y_train)\n",
    "\n",
    "    # Make predictions and add that to the train_predictions dataframe\n",
    "    train_predictions['feature b multiple rfe k=9'] = lm.predict(X_train_rfe)\n",
    "    validate_predictions['feature b multiple rfe k=9', k] = lm.predict(X_validate_rfe)\n",
    "    test_predictions['feature b multiple rfe k=9', k] = lm.predict(X_test_rfe)\n",
    "    \n",
    "    # Polynomial degree 2\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "    poly.fit(X_train)\n",
    "    X_train_poly = pd.DataFrame(\n",
    "        poly.transform(X_train),\n",
    "        columns=poly.get_feature_names(X_train.columns),\n",
    "        index=X_train.index,\n",
    "    )\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train_poly, y_train)\n",
    "\n",
    "    X_validate_poly = poly.transform(X_validate)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    train_predictions['feature b polynomial degree 2'] = lm.predict(X_train_poly)\n",
    "    validate_predictions['feature b polynomial degree 2'] = lm.predict(X_validate_poly)\n",
    "    test_predictions['feature b polynomial degree 2'] = lm.predict(X_test_poly)\n",
    "    \n",
    "    return train_predictions, validate_predictions, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40395e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_c_models(train, validate, test, train_predictions, validate_predictions, test_predictions):\n",
    "    cols = ['living_sqft', 'structure_value', 'assessed_value', 'land_value',\n",
    "       'county_Los Angeles', 'county_Orange', 'county_Ventura',\n",
    "       'zip_bin_insgfnt high', 'zip_bin_sgfnt high', 'location_clusters_0',\n",
    "       'location_clusters_2', 'location_clusters_3', 'age_clusters_0',\n",
    "       'area_clusters_1', 'area_clusters_2', 'size_clusters_0',\n",
    "       'value_clusters_0']\n",
    "    \n",
    "    # Notes: I looped through k and found out the model performs the best when k=9\n",
    "    # Initiate the linear regression model\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    # Transform our X\n",
    "    rfe = RFE(lm, n_features_to_select=6)\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Use the transformed x in our model\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_validate_rfe = rfe.transform(X_validate)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    lm.fit(X_train_rfe, y_train)\n",
    "\n",
    "    # Make predictions and add that to the train_predictions dataframe\n",
    "    train_predictions['feature c multiple rfe k=6'] = lm.predict(X_train_rfe)\n",
    "    validate_predictions['feature c multiple rfe k=6', k] = lm.predict(X_validate_rfe)\n",
    "    test_predictions['feature c multiple rfe k=6', k] = lm.predict(X_test_rfe)\n",
    "    \n",
    "    # Polynomial degree 2\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "    poly.fit(X_train)\n",
    "    X_train_poly = pd.DataFrame(\n",
    "        poly.transform(X_train),\n",
    "        columns=poly.get_feature_names(X_train.columns),\n",
    "        index=X_train.index,\n",
    "    )\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train_poly, y_train)\n",
    "\n",
    "    X_validate_poly = poly.transform(X_validate)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    train_predictions['feature c polynomial degree 2'] = lm.predict(X_train_poly)\n",
    "    validate_predictions['feature c polynomial degree 2'] = lm.predict(X_validate_poly)\n",
    "    test_predictions['feature c polynomial degree 2'] = lm.predict(X_test_poly)\n",
    "    \n",
    "    return train_predictions, validate_predictions, test_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
