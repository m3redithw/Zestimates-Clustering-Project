{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e5fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "\n",
    "# set columnns display format\n",
    "pd.set_option('display.max_columns', None)\n",
    "# default pandas decimal number display format\n",
    "# pd.options.display.float_format = '{:20,.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b73167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw, messy data\n",
    "df = acquire.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ba1a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "df = prepare.prep_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c28ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and split the data\n",
    "train, validate, test = prepare.split_scale(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50c8026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding location clusters A to dataframe\n",
    "cols = ['latitude', 'longitude', 'zip_bin_insgfnt high', 'zip_bin_insgfnt low',\n",
    "       'zip_bin_sgfnt high']\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(train[cols])\n",
    "\n",
    "train['location_clusters_a'] = kmeans.predict(train[cols])\n",
    "validate['location_clusters_a'] = kmeans.predict(validate[cols])\n",
    "test['location_clusters_a'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb48bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding location clusters B to dataframe\n",
    "cols = ['county_Los Angeles', 'county_Orange', 'zip_bin_insgfnt high', 'zip_bin_insgfnt low',\n",
    "       'zip_bin_sgfnt high']\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(train[cols])\n",
    "\n",
    "train['location_clusters_b'] = kmeans.predict(train[cols])\n",
    "validate['location_clusters_b'] = kmeans.predict(validate[cols])\n",
    "test['location_clusters_b'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a817343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding area clusters to dataframe - somewhat significant\n",
    "\n",
    "cols =['total_sqft', 'lot_sqft', 'living_sqft']\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(train[cols])\n",
    "\n",
    "train['area_clusters'] = kmeans.predict(train[cols])\n",
    "validate['area_clusters'] = kmeans.predict(validate[cols])\n",
    "test['area_clusters'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e4fb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding size clusters A to dataframe - not significant\n",
    "\n",
    "cols = ['bedrooms', 'bathrooms', 'full_bath']\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(train[cols])\n",
    "train['size_clusters_a'] = kmeans.predict(train[cols])\n",
    "validate['size_clusters_a'] = kmeans.predict(validate[cols])\n",
    "test['size_clusters_a'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abb6afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding size clusters B to dataframe - not significant\n",
    "\n",
    "cols = ['bedrooms', 'bathrooms', 'full_bath', 'roomcnt']\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(train[cols])\n",
    "train['size_clusters_b'] = kmeans.predict(train[cols])\n",
    "validate['size_clusters_b'] = kmeans.predict(validate[cols])\n",
    "test['size_clusters_b'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8614e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding value clusters to dataframe - not significant\n",
    "\n",
    "cols = ['structure_value', 'assessed_value', 'land_value','taxamount']\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(train[cols])\n",
    "train['value_clusters'] = kmeans.predict(train[cols])\n",
    "validate['value_clusters'] = kmeans.predict(validate[cols])\n",
    "test['value_clusters'] = kmeans.predict(test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da46ebdd",
   "metadata": {},
   "source": [
    "- ['age', 'location_clusters_a', 'area_clusters','size_clusters_a','value_clusters','transaction_month']\n",
    "    Train:\n",
    "    (multiple_rfe_k=, 4)    0.363455\n",
    "    (multiple_rfe_k=, 5)    0.363463\n",
    "    (multiple_rfe_k=, 2)    0.363488\n",
    "    (multiple_rfe_k=, 3)    0.363528\n",
    "    baseline                0.364527\n",
    "    \n",
    "    Validate:\n",
    "    (multiple_rfe_k=, 4)    0.364318\n",
    "    (multiple_rfe_k=, 5)    0.364327\n",
    "    (multiple_rfe_k=, 2)    0.364370\n",
    "    (multiple_rfe_k=, 3)    0.364388\n",
    "    basline                 0.366898\n",
    "    \n",
    "    **Polynomial k=2**\n",
    "    Basline (0.16262411066536314, 0.15806831374792724)\n",
    "    (0.16163094482814297, 0.1576410238958071)\n",
    "    \n",
    "    Polynomial k=3\n",
    "    (0.16097933947491191, 0.15775996884892424)\n",
    "    \n",
    "    Lasso-Lars\n",
    "    (0.16262411066536314, 0.1580787480680725)\n",
    "    \n",
    "- ['age', 'location_clusters_a', 'total_sqft','lot_sqft','size_clusters_a','value_clusters','transaction_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "314283f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set x and y\n",
    "cols = ['age', 'location_clusters_a', 'total_sqft','lot_sqft','size_clusters_a','value_clusters','transaction_month']\n",
    "\n",
    "X_train = train[cols]\n",
    "y_train = train.logerror\n",
    "\n",
    "X_validate = validate[cols]\n",
    "y_validate = validate.logerror\n",
    "\n",
    "X_test = test[cols]\n",
    "y_test = test.logerror"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1dba80",
   "metadata": {},
   "source": [
    "## Multiple  Regression + RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ea6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected top 3 features: Index(['age', 'location_clusters_a', 'area_clusters', 'size_clusters_a',\n",
      "       'size_clusters_b'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "k = 3\n",
    "\n",
    "# 1. Transform our X\n",
    "rfe = RFE(lm, n_features_to_select=5)\n",
    "rfe.fit(X_train, y_train)\n",
    "print('selected top 3 features:', X_train.columns[rfe.support_])\n",
    "X_train_rfe = rfe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e51fc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = pd.DataFrame({\n",
    "    'actual': y_train.logerror\n",
    "}) \n",
    "validate_predictions = pd.DataFrame({\n",
    "    'actual': y_validate\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "081f54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions['baseline'] = y_train.mean()\n",
    "validate_predictions['basline']=y_validate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fd10e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,6):\n",
    "    lm = LinearRegression()\n",
    "    # 1. Transform our X\n",
    "    rfe = RFE(lm, n_features_to_select=k)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    # 2. Use the transformed x in our model\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_validate_rfe = rfe.transform(X_validate)\n",
    "    lm.fit(X_train_rfe, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions['multiple_rfe_k=', k] = lm.predict(X_train_rfe)\n",
    "    validate_predictions['multiple_rfe_k=', k] = lm.predict(X_validate_rfe)\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e2102ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual                  0.000000\n",
       "(multiple_rfe_k=, 4)    0.363455\n",
       "(multiple_rfe_k=, 5)    0.363463\n",
       "(multiple_rfe_k=, 2)    0.363488\n",
       "(multiple_rfe_k=, 3)    0.363528\n",
       "baseline                0.364527\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_rmse(y_predicted):\n",
    "    return mean_squared_error(train_predictions.actual, y_predicted, squared = False)\n",
    "\n",
    "train_predictions.apply(calculate_rmse).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "589255a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual                  0.000000\n",
       "(multiple_rfe_k=, 4)    0.364318\n",
       "(multiple_rfe_k=, 5)    0.364327\n",
       "(multiple_rfe_k=, 2)    0.364370\n",
       "(multiple_rfe_k=, 3)    0.364388\n",
       "basline                 0.366898\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_rmse(y_predicted):\n",
    "    return mean_squared_error(validate_predictions.actual, y_predicted, squared = False)\n",
    "\n",
    "validate_predictions.apply(calculate_rmse).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef80fa0",
   "metadata": {},
   "source": [
    "## Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cd99a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = pd.DataFrame({\n",
    "    'actual': train.logerror\n",
    "}) \n",
    "validate_pred = pd.DataFrame({\n",
    "    'actual': validate.logerror\n",
    "}) \n",
    "train_pred['baseline'] = y_train.mean()\n",
    "validate_pred['basline']=y_validate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd3aa6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# 1. Generate Polynomial Features, k=2\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=X_train.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f26de2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "train_pred['baseline'] = y_train.mean()\n",
    "validate_pred['baseline'] = y_validate.mean()\n",
    "train_pred['polynomial degree 2'] = lm.predict(X_train_poly)\n",
    "validate_pred['polynomial degree 2'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40841969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16262411066536314"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_rmse = mean_squared_error(train_pred.actual,train_pred['baseline'], squared = False)\n",
    "baseline_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "051f74ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15806831374792724"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['baseline'], squared = False)\n",
    "validate_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d914ac7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16163094482814297, 0.1576410238958071)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(train_pred.actual,train_pred['polynomial degree 2'], squared = False)\n",
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['polynomial degree 2'], squared = False)\n",
    "train_rmse, validate_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94ec6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction terms only\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=X_train.index,\n",
    ")\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "train_pred['polynomial degree 2 only interaction'] = lm.predict(X_train_poly)\n",
    "validate_pred['polynomial degree 2 only interaction'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7d28752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16223911452454318, 0.15809481556209198)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(train_pred.actual,train_pred['polynomial degree 2 only interaction'], squared = False)\n",
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['polynomial degree 2 only interaction'], squared = False)\n",
    "train_rmse, validate_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a866564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=3\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=X_train.index,\n",
    ")\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "train_pred['baseline'] = y_train.mean()\n",
    "validate_pred['baseline'] = y_validate.mean()\n",
    "train_pred['polynomial degree 3'] = lm.predict(X_train_poly)\n",
    "validate_pred['polynomial degree 3'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0557fc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16097933947491191, 0.15775996884892424)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(train_pred.actual,train_pred['polynomial degree 3'], squared = False)\n",
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['polynomial degree 3'], squared = False)\n",
    "train_rmse, validate_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84a4e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=4\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False, interaction_only=False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = pd.DataFrame(\n",
    "    poly.transform(X_train),\n",
    "    columns=poly.get_feature_names(X_train.columns),\n",
    "    index=X_train.index,\n",
    ")\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_poly, y_train)\n",
    "X_validate_poly = poly.transform(X_validate)\n",
    "train_pred['baseline'] = y_train.mean()\n",
    "validate_pred['baseline'] = y_validate.mean()\n",
    "train_pred['polynomial degree 4'] = lm.predict(X_train_poly)\n",
    "validate_pred['polynomial degree 4'] = lm.predict(X_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "068107b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1603366092078218, 0.15824011533835622)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(train_pred.actual,train_pred['polynomial degree 4'], squared = False)\n",
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['polynomial degree 4'], squared = False)\n",
    "train_rmse, validate_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf87331",
   "metadata": {},
   "source": [
    "## Lasso-Lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9af70589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=1)\n",
    "\n",
    "# fit the model to our training data\n",
    "lars.fit(X_train, y_train)\n",
    "\n",
    "# predict validate\n",
    "X_train_pred_lars = lars.predict(X_train)\n",
    "X_validate_pred_lars = lars.predict(X_validate)\n",
    "# Add lassolars predictions to our predictions DataFrame\n",
    "train_pred['lasso_lars'] = X_train_pred_lars\n",
    "validate_pred['lasso_lars'] = X_validate_pred_lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "083f1a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16262411066536314, 0.1580787480680725)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(train_pred.actual,train_pred['lasso_lars'], squared = False)\n",
    "validate_rmse = mean_squared_error(validate_pred.actual,validate_pred['lasso_lars'], squared = False)\n",
    "train_rmse, validate_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d61ef2",
   "metadata": {},
   "source": [
    "## Generalized Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a70140f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some value(s) of y are out of the valid range for family TweedieDistribution",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m glm \u001b[38;5;241m=\u001b[39m TweedieRegressor(power\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# fit the model to our training data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mglm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# predict train\u001b[39;00m\n\u001b[1;32m     10\u001b[0m X_train_predict_glm \u001b[38;5;241m=\u001b[39m glm\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_glm/glm.py:263\u001b[0m, in \u001b[0;36mGeneralizedLinearRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    260\u001b[0m _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(family\u001b[38;5;241m.\u001b[39min_y_range(y)):\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome value(s) of y are out of the valid range for family \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    265\u001b[0m             family\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    266\u001b[0m         )\n\u001b[1;32m    267\u001b[0m     )\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# TODO: if alpha=0 check that X is not rank deficient\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# rescaling of sample_weight\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# we rescale weights such that sum(weights) = 1 and this becomes\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# 1/2*deviance + L2 with deviance=sum(weights * unit_deviance)\u001b[39;00m\n\u001b[1;32m    277\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m/\u001b[39m weights\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mValueError\u001b[0m: Some value(s) of y are out of the valid range for family TweedieDistribution"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import TweedieRegressor\n",
    "\n",
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "# fit the model to our training data\n",
    "glm.fit(X_train, y_train)\n",
    "\n",
    "# predict train\n",
    "X_train_predict_glm = glm.predict(X_train)\n",
    "X_validate_predict_glm = glm.predict(X_validate)\n",
    "# Add lassolars predictions to our predictions DataFrame\n",
    "train_pred['glm'] = X_train_predict_glm\n",
    "validate_pred['glm'] = X_validate_predict_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b34e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
